# Triple navigation evaluation

The evaluation of the [triple search](../approaches/navigate-semantic-triples-by-finite-choices.md) was carried out on a list of ==100 questions== that where generated by ```gpt-4-turbo```. The requirement for these questions was, that they can be answered by providing a semantic triple. For each question the navigating agent and the generating agent performed a search of a ==maximum of ten iterations== for a triple that is answering the question. They started from the triple ```["Physics", "is a branch of", "Science"]``` and the topic ```"Physics"```.

The whole process was conducted twice. Once with ```gpt-3.5-turbo``` as navigating and generating agent and once with ```gpt-4-turbo``` as navigating and generating agent. The examining agent was in both cases ```gpt-4-turbo```.

Here is an example for a successful triple search of the ```gpt-4-turbo``` model: The search for the answer of the question `"What protects Earth from solar radiation?"`

| Iteration | Triple                                                                    | Topic                  |
| --------- | ------------------------------------------------------------------------- | ---------------------- |
| 0         | `["Physics", "is a branch of", "Science"]`                                | Physics                |
| 1         | `["Magnetism", "is studied as a branch of", "Science"]`                   | Electromagnetism       |
| 2         | `["Magnetism", "is a key component of", "Electromagnetism"]`              | Electromagnetism       |
| 3         | `["Dynamo theory", "explains creation of", "Electromagnetism"]`           | Magnetic fields        |
| 4         | `["Protective shield around Earth", "is created by", "Electromagnetism"]` | Earth's magnetic field |
We can see how the navigation process starts from the initial triple and navigates through the knowledge base in four iteration until it reaches the triple that fulfills the condition of answering the question.

This example also shows that the examiner agent is not completely strict in the requirements that a tripe has to fulfill to answer a question. The final triple `["Protective shield around Earth", "is created by", "Electromagnetism"]` does not explicitly state, that the shield protects the earth from solar radiation.

Here is an list of five typical questions from the same dataset and the according triples that have been found by the navigation process:

| Question                                                                   | Triple                                                                                                                                  |
| -------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| What does the Tesla unit measure?                                          | `["Magnetic field", "measured in", "Tesla"]`                                                                                            |
| What attracts objects towards Earth?                                       | `["Physics", "includes", "Classical Mechanics"]`                                                                                        |
| What allows particles to overcome potential barriers in quantum mechanics? | `["Quantum tunneling", "exploits", "wave-particle duality"]`                                                                            |
| Which planet has an extensive ring system?                                 | `["Saturn", "is a mention in key terms of", "Planetary rings"]`                                                                         |
| What establishes thermal equilibrium between two objects?                  | `["Zeroth Law of Thermodynamics", "implies that", "two systems in equilibrium with a third system are in equilibrium with each other"]` |

Out of the 100 triple search runs, ```gpt-3.5-turbo``` completed 42 successful while ```gpt-4-turbo``` completed 57 successful. The calculated [decision cost](../equations/decision-cost.md) of non interrupted searches was:

|               | gpt-3.5-turbo | gpt-4-turbo |
| ------------- | ------------- | ----------- |
| decision cost | 54.3 ± 7.8    | 33.5 ± 3.9  |

These numbers correspond to the average number of navigation decisions the navigation agent has to make to find a question answering triple if there are 10 options available per decision.

[Data](https://github.com/gratach/master-database-files/tree/1db1e8c6429b09f469e9c15ea17b07eeb2835bfb/master-experimental/navigate_semantic_triples_evaluation)
[Code](https://github.com/gratach/master-experimental/blob/4f558032d96e6454d0940087e599b58f65bfd452/navigate_semantic_triples_evaluation.ipynb)
